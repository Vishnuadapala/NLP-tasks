{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YXOjeGndB6Dr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c92213f0-0baf-444b-cecc-95576b913c62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "he is\n",
            "he is well\n",
            "he is well underwaty\n",
            "he is well underwaty in\n",
            "he is well underwaty in central\n",
            "he is well underwaty in central soya\n",
            "he is well underwaty in central soya sale\n",
            "he is well underwaty in central soya sale to\n",
            "he is well underwaty in central soya sale to soriano\n",
            "he is well underwaty in central soya sale to soriano buying\n",
            "he is well underwaty in central soya sale to soriano buying the\n",
            "he is well underwaty in central soya sale to soriano buying the bank\n",
            "he is well underwaty in central soya sale to soriano buying the bank of\n",
            "he is well underwaty in central soya sale to soriano buying the bank of india\n",
            "he is well underwaty in central soya sale to soriano buying the bank of india '\n",
            "he is well underwaty in central soya sale to soriano buying the bank of india ' s\n",
            "he is well underwaty in central soya sale to soriano buying the bank of india ' s revised\n",
            "he is well underwaty in central soya sale to soriano buying the bank of india ' s revised figures\n",
            "he is well underwaty in central soya sale to soriano buying the bank of india ' s revised figures ,\n",
            "he is well underwaty in central soya sale to soriano buying the bank of india ' s revised figures , said\n"
          ]
        }
      ],
      "source": [
        "import string\n",
        "import random\n",
        "import nltk\n",
        "from nltk.corpus import stopwords, reuters\n",
        "from collections import Counter, defaultdict\n",
        "from nltk import FreqDist, ngrams\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('reuters')\n",
        "nltk.download('punkt_tab')\n",
        "sents = reuters.sents()\n",
        "stop_word = set(stopwords.words('english'))\n",
        "string.punctuation = string.punctuation + ' \" ' + ' \" ' + ' - ' + ' _ '\n",
        "removal_list = list(stop_word) + list(string.punctuation) + ['\\t', 'rt']\n",
        "unigram = []\n",
        "bigram = []\n",
        "trigram = []\n",
        "tokenized_text = []\n",
        "for sentence in sents:\n",
        "    sentence = list(map(lambda x: x.lower(), sentence))\n",
        "    for word in sentence:\n",
        "        if word == '.':\n",
        "            sentence.remove(word)\n",
        "        else:\n",
        "            unigram.append(word)\n",
        "    tokenized_text.append(word)\n",
        "    bigram.extend(list(ngrams(sentence, 2, pad_left=True, pad_right=True)))\n",
        "    trigram.extend(list(ngrams(sentence, 3, pad_left=True, pad_right=True)))\n",
        "def remove_stopwords(x):\n",
        "    y = []\n",
        "    for pair in x:\n",
        "        count = 0\n",
        "        for word in pair:\n",
        "            if word in removal_list:\n",
        "                count = count or 0\n",
        "            else:\n",
        "                count = count or 1\n",
        "        if count == 1:\n",
        "            y.append(pair)\n",
        "    return y\n",
        "unigram = remove_stopwords(unigram)\n",
        "bigram = remove_stopwords(bigram)\n",
        "trigram = remove_stopwords(trigram) 2\n",
        "freq_uni = FreqDist(unigram)\n",
        "freq_bi = FreqDist(bigram)\n",
        "freq_tri = FreqDist(trigram)\n",
        "d = defaultdict(Counter)\n",
        "for a, b, c in freq_tri:\n",
        "    if (a is not None) and (b is not None) and (c is not None):\n",
        "        d[a, b][c] += freq_tri[a, b, c]\n",
        "def pick_word(counter):\n",
        "    \"choose a random element\"\n",
        "    return random.choice(list(counter.elements()))\n",
        "prefix = \"he\", \"is\"\n",
        "print(\" \".join(prefix))\n",
        "s = \" \".join(prefix)\n",
        "for i in range(19):\n",
        "    suffix = pick_word(d[prefix])\n",
        "    s = s + ' ' + suffix\n",
        "    print(s)\n",
        "    prefix = prefix[1], suffix"
      ]
    }
  ]
}